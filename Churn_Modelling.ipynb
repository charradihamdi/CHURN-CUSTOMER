{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Modelling Using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NATIONALITY</th>\n",
       "      <th>RESIDENCE</th>\n",
       "      <th>TYPE_CLIENT</th>\n",
       "      <th>HasCrdCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>MARITAL_STATUS</th>\n",
       "      <th>ONLINE_ACTUAL_BAL</th>\n",
       "      <th>Account-AGE</th>\n",
       "      <th>Excited</th>\n",
       "      <th>ACCOUNT_OFFICER</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10B3FCECB5122943,122,male,TN,TN,PP,0,1,others,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166E4A0E75E88A93,122,male,FR,TN,PP,1,1,others,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371B594EEE3591C8,122,male,AU,AU,PP,1,0,others,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443D95AA253C782F,122,male,FR,FR,PP,0,0,others,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6CB9D86C8F334663,122,male,FR,FR,PP,0,1,others,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8099D9CA287FCDCF,122,female,TN,TN,PP,1,1,other...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91CAC2F5CB979164,122,female,IT,TN,PP,1,0,other...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C46EB56BA8559C61,122,female,IT,IT,PP,0,0,other...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F7B55CCF3A0302B5,122,female,FR,FR,PP,0,0,other...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FCD8501280C91317,122,male,FR,FR,PP,1,1,others,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID  AGE  Gender  \\\n",
       "0  10B3FCECB5122943,122,male,TN,TN,PP,0,1,others,...  NaN     NaN   \n",
       "1  166E4A0E75E88A93,122,male,FR,TN,PP,1,1,others,...  NaN     NaN   \n",
       "2  371B594EEE3591C8,122,male,AU,AU,PP,1,0,others,...  NaN     NaN   \n",
       "3  443D95AA253C782F,122,male,FR,FR,PP,0,0,others,...  NaN     NaN   \n",
       "4  6CB9D86C8F334663,122,male,FR,FR,PP,0,1,others,...  NaN     NaN   \n",
       "5  8099D9CA287FCDCF,122,female,TN,TN,PP,1,1,other...  NaN     NaN   \n",
       "6  91CAC2F5CB979164,122,female,IT,TN,PP,1,0,other...  NaN     NaN   \n",
       "7  C46EB56BA8559C61,122,female,IT,IT,PP,0,0,other...  NaN     NaN   \n",
       "8  F7B55CCF3A0302B5,122,female,FR,FR,PP,0,0,other...  NaN     NaN   \n",
       "9  FCD8501280C91317,122,male,FR,FR,PP,1,1,others,...  NaN     NaN   \n",
       "\n",
       "   NATIONALITY  RESIDENCE  TYPE_CLIENT  HasCrdCard  IsActiveMember  \\\n",
       "0          NaN        NaN          NaN         NaN             NaN   \n",
       "1          NaN        NaN          NaN         NaN             NaN   \n",
       "2          NaN        NaN          NaN         NaN             NaN   \n",
       "3          NaN        NaN          NaN         NaN             NaN   \n",
       "4          NaN        NaN          NaN         NaN             NaN   \n",
       "5          NaN        NaN          NaN         NaN             NaN   \n",
       "6          NaN        NaN          NaN         NaN             NaN   \n",
       "7          NaN        NaN          NaN         NaN             NaN   \n",
       "8          NaN        NaN          NaN         NaN             NaN   \n",
       "9          NaN        NaN          NaN         NaN             NaN   \n",
       "\n",
       "   MARITAL_STATUS  ONLINE_ACTUAL_BAL  Account-AGE  Excited  ACCOUNT_OFFICER  \\\n",
       "0             NaN                NaN          NaN      NaN              NaN   \n",
       "1             NaN                NaN          NaN      NaN              NaN   \n",
       "2             NaN                NaN          NaN      NaN              NaN   \n",
       "3             NaN                NaN          NaN      NaN              NaN   \n",
       "4             NaN                NaN          NaN      NaN              NaN   \n",
       "5             NaN                NaN          NaN      NaN              NaN   \n",
       "6             NaN                NaN          NaN      NaN              NaN   \n",
       "7             NaN                NaN          NaN      NaN              NaN   \n",
       "8             NaN                NaN          NaN      NaN              NaN   \n",
       "9             NaN                NaN          NaN      NaN              NaN   \n",
       "\n",
       "   Id  \n",
       "0 NaN  \n",
       "1 NaN  \n",
       "2 NaN  \n",
       "3 NaN  \n",
       "4 NaN  \n",
       "5 NaN  \n",
       "6 NaN  \n",
       "7 NaN  \n",
       "8 NaN  \n",
       "9 NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('dataOF.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29999 entries, 0 to 29998\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   AGE                0 non-null      float64\n",
      " 1   Gender             0 non-null      float64\n",
      " 2   NATIONALITY        0 non-null      float64\n",
      " 3   RESIDENCE          0 non-null      float64\n",
      " 4   TYPE_CLIENT        0 non-null      float64\n",
      " 5   HasCrdCard         0 non-null      float64\n",
      " 6   IsActiveMember     0 non-null      float64\n",
      " 7   MARITAL_STATUS     0 non-null      float64\n",
      " 8   ONLINE_ACTUAL_BAL  0 non-null      float64\n",
      " 9   Account-AGE        0 non-null      float64\n",
      " 10  Excited            0 non-null      float64\n",
      " 11  ACCOUNT_OFFICER    0 non-null      float64\n",
      " 12  Id                 0 non-null      float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Below Info Function will print detail information on the dataset that was imported in the previous step.\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data Set into Dependent and Independent Variable.\n",
    "X = dataset.iloc[:, 3:10].values\n",
    "y = dataset.iloc[:, 11].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below step will be performed again after encoding the categorical variables. This is being done for the final submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have two categorical variables (“Country” and “Gender” variable) in our data. We need to encode them. I used labelencoder and onehotencoder of scikit-learn package to achieve this. Note that I removed a dummy variable of “Country” to avoid falling into dummy variable trap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'categorical_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12556/3526101936.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabelencoder_X_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabelencoder_X_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0monehotencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monehotencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'categorical_features'"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling is a method used to standardize the range of independent variables or features of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'FR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12556/1930884711.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \"\"\"\n\u001b[0;32m    765\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[0;32m    767\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m                                 force_all_finite='allow-nan', reset=first_call)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'FR'"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now our data is well preprocessed and now we will build the artificial neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Tensorflow and Keras Library To Build ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12556/3793406994.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The sequential module is required to initialize the ann and dense module is required to add layers to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will initialize the deep learning model as a sequence of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have defined 6 units in the first hidden layer and used rectifying linear function(ReLu) as the activation function. And since input dimensions(no. of features) are 11 we will define input_dim=11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the output layer....It will have one output unit and we will use sigmoid function since it’s a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.4760 - acc: 0.7960\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.4291 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.4231 - acc: 0.7964\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4184 - acc: 0.8222\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4161 - acc: 0.8265\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4140 - acc: 0.8311\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.4127 - acc: 0.8327\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.4113 - acc: 0.8324\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4104 - acc: 0.8342\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4093 - acc: 0.8331\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4079 - acc: 0.8347\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.4080 - acc: 0.8360\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4071 - acc: 0.8341\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4066 - acc: 0.8330: 1s \n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4060 - acc: 0.8361A: 0s - loss: 0.4\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 8s 952us/step - loss: 0.4055 - acc: 0.8345\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 8s 992us/step - loss: 0.4055 - acc: 0.8340\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4050 - acc: 0.8345\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 8s 943us/step - loss: 0.4041 - acc: 0.8352\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 8s 940us/step - loss: 0.4045 - acc: 0.8344\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4042 - acc: 0.8355\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4037 - acc: 0.8365\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4034 - acc: 0.8345\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4037 - acc: 0.8340\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4029 - acc: 0.8352\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4033 - acc: 0.8351\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4030 - acc: 0.8357\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4031 - acc: 0.8341\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4023 - acc: 0.8357\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4026 - acc: 0.8337\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4029 - acc: 0.8347\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4025 - acc: 0.8362\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4018 - acc: 0.8366\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 6s 798us/step - loss: 0.4024 - acc: 0.8350\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 6s 787us/step - loss: 0.4021 - acc: 0.8350\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 6s 799us/step - loss: 0.4014 - acc: 0.8355\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 0.4013 - acc: 0.8344\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 6s 780us/step - loss: 0.4016 - acc: 0.8366 0s - loss: 0.4018 - acc: 0.8\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 7s 817us/step - loss: 0.4012 - acc: 0.8359\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 6s 785us/step - loss: 0.4015 - acc: 0.8360\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 6s 756us/step - loss: 0.4009 - acc: 0.8365\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 7s 820us/step - loss: 0.4010 - acc: 0.8349\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 6s 807us/step - loss: 0.4011 - acc: 0.8359\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 6s 741us/step - loss: 0.4009 - acc: 0.8357\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 6s 787us/step - loss: 0.4009 - acc: 0.8357\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 7s 825us/step - loss: 0.4009 - acc: 0.8351\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 6s 748us/step - loss: 0.4012 - acc: 0.8361\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 6s 695us/step - loss: 0.4009 - acc: 0.8345\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 6s 730us/step - loss: 0.4005 - acc: 0.8339\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 5s 672us/step - loss: 0.4008 - acc: 0.8360\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 6s 711us/step - loss: 0.4008 - acc: 0.8359\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 5s 654us/step - loss: 0.4005 - acc: 0.8366\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 5s 638us/step - loss: 0.4010 - acc: 0.8347\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 5s 645us/step - loss: 0.4003 - acc: 0.8366\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 5s 657us/step - loss: 0.4008 - acc: 0.8361\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 6s 692us/step - loss: 0.4004 - acc: 0.8360\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 5s 673us/step - loss: 0.4002 - acc: 0.8352\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 5s 591us/step - loss: 0.3997 - acc: 0.8364\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 5s 645us/step - loss: 0.4000 - acc: 0.8349\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 5s 626us/step - loss: 0.4000 - acc: 0.8346\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 6s 692us/step - loss: 0.3997 - acc: 0.8344\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 5s 630us/step - loss: 0.3998 - acc: 0.8375\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 6s 704us/step - loss: 0.3996 - acc: 0.8352\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 5s 614us/step - loss: 0.4004 - acc: 0.8351\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 5s 645us/step - loss: 0.3994 - acc: 0.8360\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 5s 653us/step - loss: 0.3994 - acc: 0.8361\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 6s 705us/step - loss: 0.3995 - acc: 0.8362\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 6s 709us/step - loss: 0.3995 - acc: 0.8355\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 5s 605us/step - loss: 0.3994 - acc: 0.8362\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 5s 624us/step - loss: 0.3995 - acc: 0.8364\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 5s 611us/step - loss: 0.3995 - acc: 0.8359\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 0.3989 - acc: 0.8357\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 5s 666us/step - loss: 0.3994 - acc: 0.8362\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 6s 696us/step - loss: 0.3992 - acc: 0.8355\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 5s 672us/step - loss: 0.3991 - acc: 0.8361\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 5s 637us/step - loss: 0.3991 - acc: 0.8376\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 5s 601us/step - loss: 0.3984 - acc: 0.8356\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 5s 665us/step - loss: 0.3992 - acc: 0.8360\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 6s 738us/step - loss: 0.3990 - acc: 0.8350\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 5s 650us/step - loss: 0.3990 - acc: 0.8364\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 5s 593us/step - loss: 0.3991 - acc: 0.8360\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 5s 647us/step - loss: 0.3986 - acc: 0.8367\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 5s 646us/step - loss: 0.3986 - acc: 0.8362\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.3988 - acc: 0.8360\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 5s 636us/step - loss: 0.3991 - acc: 0.8362\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 5s 674us/step - loss: 0.3988 - acc: 0.8355\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 5s 658us/step - loss: 0.3989 - acc: 0.8355\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 5s 652us/step - loss: 0.3987 - acc: 0.8351\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 5s 614us/step - loss: 0.3986 - acc: 0.8369\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 6s 726us/step - loss: 0.3987 - acc: 0.8361\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 5s 681us/step - loss: 0.3980 - acc: 0.8354\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.3982 - acc: 0.8360\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 5s 627us/step - loss: 0.3984 - acc: 0.8361\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 5s 657us/step - loss: 0.3980 - acc: 0.8366\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 5s 665us/step - loss: 0.3985 - acc: 0.8361\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 5s 649us/step - loss: 0.3988 - acc: 0.8362\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 5s 683us/step - loss: 0.3986 - acc: 0.8364\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 5s 647us/step - loss: 0.3982 - acc: 0.8377\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 5s 611us/step - loss: 0.3983 - acc: 0.8361\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 5s 633us/step - loss: 0.3984 - acc: 0.8351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d141ac630>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1541,   54],\n",
       "       [ 255,  150]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Test Data and Predicted Test Results. Writing the combined data set into CSV File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>597</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>131101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>192853</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>523</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>102967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128702</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>706</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>95386.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75732.2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>788</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>112080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89368.6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>706</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>163035</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135662</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>670</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>175576</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99061.8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>590</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>65812.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160346</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>636</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>157576</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101102</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>598</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13181.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>456</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>165351</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140758</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>498</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13892.6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>714</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>150900</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>139889</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>488</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>140002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>123614</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>562</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>117153</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108675</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>143931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46675.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>667</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>154393</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137675</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>513</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>675</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>115654</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131971</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>622</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>107879</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>196895</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>551</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51143.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>663</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>115931</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19862.8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>850</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56991.7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>552</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140287</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>444</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>144319</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112668</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>794</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68730.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>827</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>183276</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13460.3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>590</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>166931</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>122488</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>492</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>77168.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146700</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>498</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>190036</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>757</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>123322</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>137136</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>640</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>89047.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>116286</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>624</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62825</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>660</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>118402</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14288.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>721</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53534.8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>803</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115677</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>543</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>104309</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25650</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>712</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>139887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95719.7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>714</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>141173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98896.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>696</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>87637.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196111</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>715</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>160377</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196853</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>528</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>97473.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>159823</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>535</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61820.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>522</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>144148</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14789.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>528</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>104745</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>170263</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>575</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>121823</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50368.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>629</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>150149</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6936.27</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>525</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69361.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>511</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49089.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>158698</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107181</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>583</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>54428.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109639</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>494</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85890.2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>743</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>127023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138781</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>593</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>70181.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80608.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>611</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25395.8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>439</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>110976</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138527</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>625</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180970</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>586</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70760.7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>578</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>157268</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141533</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>650</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>142393</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11276.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>573</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>127406</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>192951</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1       2   3   4        5  6  7  8        9      0\n",
       "0     597  Germany  Female  35   8   131101  1  1  1   192853  False\n",
       "1     523   France  Female  40   2   102967  1  1  0   128702  False\n",
       "2     706    Spain  Female  42   8  95386.8  1  1  1  75732.2  False\n",
       "3     788   France    Male  32   4   112080  1  0  0  89368.6  False\n",
       "4     706  Germany    Male  38   5   163035  2  1  1   135662  False\n",
       "5     670    Spain  Female  57   3   175576  2  1  0  99061.8   True\n",
       "6     590    Spain    Male  34   0  65812.4  2  0  1   160346  False\n",
       "7     636    Spain  Female  29   6   157576  2  1  1   101102  False\n",
       "8     598   France  Female  64   9        0  1  0  1  13181.4  False\n",
       "9     456   France  Female  63   1   165351  2  0  0   140758   True\n",
       "10    498   France  Female  31  10        0  2  1  0  13892.6  False\n",
       "11    714    Spain    Male  45   8   150900  2  0  1   139889  False\n",
       "12    488  Germany  Female  33   4   140002  1  1  0   123614  False\n",
       "13    562  Germany  Female  31   9   117153  1  1  1   108675  False\n",
       "14    772  Germany  Female  51   9   143931  1  0  1  46675.5   True\n",
       "15    667  Germany    Male  55   9   154393  1  1  1   137675  False\n",
       "16    513   France  Female  43   9        0  2  1  0   152500  False\n",
       "17    675    Spain    Male  66   5   115654  2  1  1   131971  False\n",
       "18    622   France  Female  30   4   107879  1  0  1   196895  False\n",
       "19    551   France  Female  45   6        0  2  1  1  51143.4  False\n",
       "20    663  Germany    Male  42   7   115931  1  1  0  19862.8  False\n",
       "21    850   France    Male  35   2        0  2  1  1  56991.7  False\n",
       "22    552    Spain  Female  34   4        0  2  1  0   140287  False\n",
       "23    444   France    Male  34   2   144319  1  1  0   112668  False\n",
       "24    794   France    Male  35   6        0  2  1  1  68730.9  False\n",
       "25    827    Spain    Male  46   1   183276  1  1  1  13460.3  False\n",
       "26    590    Spain  Female  29   2   166931  2  1  0   122488  False\n",
       "27    492  Germany  Female  30  10  77168.9  2  0  1   146700  False\n",
       "28    498   France  Female  29   9        0  1  1  0   190036  False\n",
       "29    757   France  Female  44   4   123322  1  1  0   137136  False\n",
       "...   ...      ...     ...  ..  ..      ... .. .. ..      ...    ...\n",
       "1970  640    Spain    Male  47   6  89047.1  1  1  0   116286  False\n",
       "1971  624    Spain    Male  46   3        0  2  1  1    62825  False\n",
       "1972  660  Germany    Male  28   1   118402  2  1  0  14288.9  False\n",
       "1973  721    Spain    Male  38   7        0  1  0  1  53534.8  False\n",
       "1974  803   France    Male  33   6        0  2  1  0   115677  False\n",
       "1975  543   France  Female  71   1   104309  1  1  1    25650  False\n",
       "1976  712    Spain    Male  47   1   139887  1  1  1  95719.7  False\n",
       "1977  714   France    Male  34   5   141173  1  0  1  98896.1  False\n",
       "1978  696   France    Male  27   4  87637.3  2  0  0   196111  False\n",
       "1979  715   France    Male  28   7   160377  1  0  0   196853  False\n",
       "1980  528    Spain    Male  43   7  97473.9  2  1  1   159823  False\n",
       "1981  535   France  Female  49   3        0  1  0  0  61820.4   True\n",
       "1982  522   France    Male  41   5   144148  1  1  1  14789.9  False\n",
       "1983  528    Spain    Male  23   7   104745  1  1  0   170263  False\n",
       "1984  575   France    Male  29   4   121823  2  1  1  50368.9  False\n",
       "1985  629    Spain    Male  41  10   150149  1  0  0  6936.27  False\n",
       "1986  525    Spain  Female  25  10        0  2  1  0  69361.9  False\n",
       "1987  511   France    Male  27   8        0  2  1  1  49089.4  False\n",
       "1988  699   France    Male  44   8   158698  1  1  0   107181  False\n",
       "1989  583    Spain  Female  40   3  54428.4  1  1  0   109639  False\n",
       "1990  494    Spain    Male  67   5        0  2  1  1  85890.2  False\n",
       "1991  743   France  Female  30   1   127023  1  1  1   138781  False\n",
       "1992  593   France    Male  36   2  70181.5  2  1  0  80608.1  False\n",
       "1993  611   France    Male  28   2        0  2  0  0  25395.8  False\n",
       "1994  439   France    Male  28   7   110976  2  1  0   138527  False\n",
       "1995  625   France  Female  24   1        0  2  1  1   180970  False\n",
       "1996  586   France  Female  35   7        0  2  1  0  70760.7  False\n",
       "1997  578    Spain    Male  36   1   157268  2  1  0   141533  False\n",
       "1998  650  Germany    Male  34   4   142393  1  1  1  11276.5  False\n",
       "1999  573  Germany    Male  30   8   127406  1  1  0   192951  False\n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(X1_test)\n",
    "df2 = pd.DataFrame(y_pred)\n",
    "submission = pd.concat([df1,df2],axis = 1)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
